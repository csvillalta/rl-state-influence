{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Influence Calculation Outline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import gin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import models\n",
    "import utils\n",
    "\n",
    "from dqn import DQN\n",
    "from circle import CircleEnv\n",
    "\n",
    "# Load configuration for DQN and model\n",
    "gin.parse_config_file('configs/influence/influence.gin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we train our __oracle network__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  0 | Start: (-2.75,  0.25) | Return:  2.69 | e: 0.9801\n",
      "Episode:  1 | Start: (-3.50,  2.25) | Return:  1.01 | e: 0.9606\n",
      "Episode:  2 | Start: ( 0.75,  2.75) | Return:  1.69 | e: 0.9415\n",
      "Episode:  3 | Start: ( 1.00,  1.25) | Return:  2.52 | e: 0.9227\n",
      "Episode:  4 | Start: ( 1.25,  0.00) | Return:  3.10 | e: 0.9044\n",
      "Episode:  5 | Start: ( 3.00, -3.25) | Return:  0.82 | e: 0.8864\n",
      "Episode:  6 | Start: (-2.75,  3.00) | Return:  0.79 | e: 0.8687\n",
      "Episode:  7 | Start: (-3.75,  0.00) | Return:  0.91 | e: 0.8515\n",
      "Episode:  8 | Start: ( 0.50, -2.25) | Return:  2.10 | e: 0.8345\n",
      "Episode:  9 | Start: (-0.75,  3.50) | Return:  1.15 | e: 0.8179\n",
      "Episode: 10 | Start: ( 3.75,  0.75) | Return:  0.82 | e: 0.8016\n",
      "Episode: 11 | Start: ( 3.50,  3.25) | Return:  0.61 | e: 0.7857\n",
      "Episode: 12 | Start: ( 1.00, -1.50) | Return:  2.32 | e: 0.7700\n",
      "Episode: 13 | Start: ( 0.00,  1.25) | Return:  2.42 | e: 0.7547\n",
      "Episode: 14 | Start: (-0.50, -1.75) | Return:  1.93 | e: 0.7397\n",
      "Episode: 15 | Start: (-2.25,  2.75) | Return:  0.91 | e: 0.7250\n",
      "Episode: 16 | Start: (-3.00,  3.25) | Return:  0.60 | e: 0.7106\n",
      "Episode: 17 | Start: ( 2.50,  3.00) | Return:  0.91 | e: 0.6964\n",
      "Episode: 18 | Start: ( 1.00,  3.75) | Return:  0.82 | e: 0.6826\n",
      "Episode: 19 | Start: (-0.25,  0.75) | Return:  9.80 | e: 0.6690\n",
      "Episode: 20 | Start: ( 3.50, -2.25) | Return:  0.71 | e: 0.6557\n",
      "Episode: 21 | Start: (-3.75, -2.25) | Return:  0.73 | e: 0.6426\n",
      "Episode: 22 | Start: (-1.75,  0.25) | Return:  1.99 | e: 0.6298\n",
      "Episode: 23 | Start: (-3.00, -1.25) | Return:  1.01 | e: 0.6173\n",
      "Episode: 24 | Start: (-3.00, -0.50) | Return:  1.16 | e: 0.6050\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Documents/haverford/rl-state-influence/dqn.py\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mtarget_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mtarget_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 self.training_data.append((state[0][0], \n\u001b[1;32m     83\u001b[0m                                            \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/thesis/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/thesis/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                 zip(y, sample_weights, class_weights,\n\u001b[0;32m--> 801\u001b[0;31m                     feed_sample_weight_modes)\n\u001b[0m\u001b[1;32m    802\u001b[0m             ]\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/thesis/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    797\u001b[0m             sample_weights = [\n\u001b[1;32m    798\u001b[0m                 \u001b[0mstandardize_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m                 zip(y, sample_weights, class_weights,\n\u001b[1;32m    801\u001b[0m                     feed_sample_weight_modes)\n",
      "\u001b[0;32m~/.virtualenvs/thesis/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_weights\u001b[0;34m(y, sample_weight, class_weight, sample_weight_mode)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/thesis/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, order)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "episodes = 80\n",
    "steps = 25\n",
    "\n",
    "oracle = DQN()\n",
    "oracle.model.save('oracle_init_model.h5')\n",
    "oracle.target_model.save('oracle_init_target_model.h5')\n",
    "\n",
    "env = CircleEnv()\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    start = state\n",
    "    total_reward = 0\n",
    "    for step in range(steps):\n",
    "#         env.render()\n",
    "        action = oracle.act(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        oracle.remember((state, action, reward, next_state, episode, step, done))\n",
    "        oracle.replay()\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        \n",
    "        if done or step==steps-1:\n",
    "            print(\"Episode: {:2} | Start: ({:5.2f}, {:5.2f}) | Return: {:5.2f} | e: {:.4f}\".format(episode, start[0], start[1], total_reward, oracle.epsilon))\n",
    "            break\n",
    "\n",
    "        if step%10==0 and step>0:\n",
    "            if oracle.epsilon >= oracle.epsilon_min:\n",
    "                oracle.epsilon *= oracle.epsilon_decay\n",
    "            oracle.update_target_model()\n",
    "\n",
    "oracle.save_training_data('oracle_training_data.h5')\n",
    "oracle.model.save('oracle_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's demo our oracle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "demo_env = CircleEnv()\n",
    "utils.demo_agent(oracle, demo_env, 10, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load in the necessary oracle data from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_model = 'oracle_model.h5'\n",
    "oracle_init_model = 'oracle_init_model.h5'\n",
    "oracle_init_target_model = 'oracle_init_target_model.h5'\n",
    "oracle_training_data = 'oracle_training_data.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the training data and setting up the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_hdf(oracle_training_data, key='training')\n",
    "%time test_data = utils.generate_agent_actions(oracle, n=10000)\n",
    "\n",
    "print(training_data.info())\n",
    "print('='*40)\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect our training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame with every unique state from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_states = training_data[['state_x', 'state_y']].drop_duplicates()\n",
    "print(unique_states.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the meat of the calculations: the __loop__. (Might want to consider creating an *influence function* and call apply on the rows of `unique_states` which may be faster than looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should return a DataFrame with influences for each unique_state\n",
    "# unique_states.apply(utils.influence, {training_data: training_data, test_data: test_data})\n",
    "# Combine unique_state and influence Series into a DataFrame (probably want this in or influence function...)\n",
    "\n",
    "# TODO: Aggregate by taking the max influence per unique state.\n",
    "for _, state in unique_states.iterrows():\n",
    "    # Why is there a need to drop duplicates here?\n",
    "    state_occurences = training_data[(training_data['state_x'] == state[0]) & \n",
    "                            (training_data['state_y'] == state[1])].drop_duplicates()\n",
    "\n",
    "    for _, state_occurence in state_occurences.iterrows():\n",
    "        episode, step = state_occurence['episode'], state_occurence['step']\n",
    "        \n",
    "        # Every state except those that occurs on or after the above step during the above episode.\n",
    "        full_trace = training_data[(training_data['episode'] != episode) | \n",
    "                          (training_data['step'] < step)]\n",
    "        # Every state except those that occur after the above step during the above episode.\n",
    "        partial_trace = training_data[(training_data['episode'] != episode) | \n",
    "                             (training_data['step'] <= step)]\n",
    "        \n",
    "        # Setup our two agents to train on each of the modified training sets above.\n",
    "        ft_agent = DQN()\n",
    "        ft_agent.model.load_weights(oracle_init_model)\n",
    "        ft_agent.target_model.load_weights(oracle_init_target_model)\n",
    "        \n",
    "        pt_agent = DQN()\n",
    "        pt_agent.model.load_weights(oracle_init_model)\n",
    "        pt_agent.target_model.load_weights(oracle_init_target_model)\n",
    "        \n",
    "        # Train our agents and get their optimal actions on testing data.\n",
    "        utils.train_agent_offline(ft_agent, full_trace.to_numpy())\n",
    "        utils.train_agent_offline(pt_agent, partial_trace.to_numpy())\n",
    "        \n",
    "        ft_agent_actions = utils.get_agent_actions(ft_agent, test_data[['state_x', 'state_y']])\n",
    "        pt_agent_actions = utils.get_agent_actions(pt_agent, test_data[['state_x', 'state_y']])\n",
    "        \n",
    "        # Get accuracies.\n",
    "        ft_agent_acc = utils.agent_accuracy(ft_agent_actions, test_data['action'].to_numpy())\n",
    "        pt_agent_acc = utils.agent_accuracy(pt_agent_actions, test_data['action'].to_numpy())\n",
    "        \n",
    "        # Relative influence.\n",
    "        delta_acc = ft_agent_acc - pt_agent_acc\n",
    "        print(\"Influence of ({:5.2f}, {:5.2f}) at episode {:2}, step {:2}: {:.4f}\".format(state_occurence['state_x'], \n",
    "                                                                        state_occurence['state_y'],\n",
    "                                                                        state_occurence['episode'], \n",
    "                                                                        state_occurence['step'], \n",
    "                                                                        np.round(delta_acc, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing to make sure that our retraining step is training properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_agent = DQN()\n",
    "test_agent.model.load_weights(oracle_init_model)\n",
    "test_agent.target_model.load_weights(oracle_init_target_model)\n",
    "\n",
    "utils.train_agent_offline(test_agent, training_data.to_numpy())\n",
    "test_agent_actions = utils.get_agent_actions(test_agent, test_data[['state_x', 'state_y']])\n",
    "acc = utils.agent_accuracy(test_agent_actions, test_data['action'])\n",
    "print(acc)\n",
    "assert acc == 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
